{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Portfolio Analysis (Schwab CSV Compatible)\n",
    "\n",
    "This notebook is designed to be **scrupulous and comprehensive** while remaining practical. It focuses on Schwab CSV exports and adds optional enrichment with market data. It is built to be flexible about column names and to tolerate real-world CSV quirks.\n",
    "\n",
    "**You will get:**\n",
    "- Robust CSV ingestion for Schwab holdings and transactions\n",
    "- Portfolio summary, allocation, concentration, and quality checks\n",
    "- Performance and risk metrics (if price data is available)\n",
    "- Optional enrichment with sector/industry metadata\n",
    "- Rebalancing and risk contribution analysis\n",
    "- Exportable outputs and figures\n",
    "\n",
    "**Data you can use:**\n",
    "- Schwab holdings CSV (Positions or Holdings export)\n",
    "- Schwab transaction history CSV (if available)\n",
    "- Local price history CSV (recommended if no API access)\n",
    "- Optional API via `yfinance` (requires network access)\n",
    "\n",
    "If you have different export formats, update the column mapping in the normalization utilities below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Environment setup\n",
    "\n",
    "This notebook uses common analytics libraries. If a library is missing, install it in your environment.\n",
    "\n",
    "Recommended: `pandas`, `numpy`, `matplotlib`, `seaborn`, `scipy`, `statsmodels`, `yfinance` (optional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional install commands (uncomment if needed)\n",
    "# !pip install pandas numpy matplotlib seaborn scipy statsmodels yfinance\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
    "CACHE_DIR = BASE_DIR / \"cache\"\n",
    "\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration\n",
    "\n",
    "Update paths and options as needed.\n",
    "- `holdings_csv`: Schwab positions/holdings export\n",
    "- `transactions_csv`: Schwab transaction history export\n",
    "- `prices_csv`: local price history with columns `date`, `symbol`, `adj_close` (or `close`)\n",
    "- `benchmark_symbol`: used for beta and relative performance\n",
    "\n",
    "Tip: Keep data in the `data/` folder for convenience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"holdings_csv\": DATA_DIR / \"schwab_holdings.csv\",\n",
    "    \"transactions_csv\": DATA_DIR / \"schwab_transactions.csv\",\n",
    "    \"prices_csv\": DATA_DIR / \"prices.csv\",\n",
    "    \"benchmark_symbol\": \"SPY\",\n",
    "    \"analysis_currency\": \"USD\",\n",
    "    \"risk_free_rate_annual\": 0.03,\n",
    "    \"use_yfinance\": False,\n",
    "    \"yfinance_period\": \"5y\",\n",
    "    \"yfinance_interval\": \"1d\",\n",
    "}\n",
    "\n",
    "CONFIG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Utilities: normalization and parsing\n",
    "\n",
    "Schwab CSV exports can vary in column headers and formatting. The utilities below aim to normalize them into a consistent schema.\n",
    "\n",
    "If your CSV uses different column names, extend `COLUMN_ALIASES`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "COLUMN_ALIASES = {\n",
    "    # Holdings / Positions\n",
    "    \"symbol\": [\"symbol\", \"ticker\", \"sym\"],\n",
    "    \"description\": [\"description\", \"security description\", \"name\", \"security name\"],\n",
    "    \"quantity\": [\"quantity\", \"qty\", \"shares\", \"units\"],\n",
    "    \"price\": [\"price\", \"last price\", \"mark\", \"market price\"],\n",
    "    \"market_value\": [\"market value\", \"marketvalue\", \"value\"],\n",
    "    \"cost_basis\": [\"cost basis\", \"costbasis\", \"total cost\"],\n",
    "    \"unrealized_gain\": [\"unrealized gain\", \"unrealized\", \"unrealized gain/loss\", \"unrealized pl\"],\n",
    "    \"unrealized_gain_pct\": [\"unrealized gain %\", \"unrealized %\", \"unrealized gain/loss %\"],\n",
    "    \"day_change\": [\"day change\", \"change $\", \"day change $\"],\n",
    "    \"day_change_pct\": [\"day change %\", \"change %\"],\n",
    "    \"asset_class\": [\"asset class\", \"assetclass\", \"asset type\"],\n",
    "    # Transactions\n",
    "    \"trade_date\": [\"date\", \"trade date\", \"posted date\"],\n",
    "    \"action\": [\"action\", \"transaction\", \"type\"],\n",
    "    \"amount\": [\"amount\", \"net amount\", \"total amount\"],\n",
    "    \"fees\": [\"fees\", \"commission\"],\n",
    "    \"cash\": [\"cash\", \"cash balance\"],\n",
    "}\n",
    "\n",
    "def _norm_col(col):\n",
    "    col = str(col).strip().lower()\n",
    "    col = re.sub(r\"\\s+\", \" \", col)\n",
    "    col = col.replace(\"/\", \" \" ).replace(\"-\", \" \" )\n",
    "    col = re.sub(r\"[^a-z0-9 %]\", \"\", col)\n",
    "    col = re.sub(r\"\\s+\", \" \", col).strip()\n",
    "    return col\n",
    "\n",
    "def normalize_columns(df):\n",
    "    raw_cols = list(df.columns)\n",
    "    norm_cols = {_norm_col(c): c for c in raw_cols}\n",
    "\n",
    "    mapping = {}\n",
    "    for canonical, aliases in COLUMN_ALIASES.items():\n",
    "        for alias in aliases:\n",
    "            alias_norm = _norm_col(alias)\n",
    "            if alias_norm in norm_cols:\n",
    "                mapping[norm_cols[alias_norm]] = canonical\n",
    "                break\n",
    "\n",
    "    df = df.rename(columns=mapping)\n",
    "    return df\n",
    "\n",
    "def to_float(series):\n",
    "    if series is None:\n",
    "        return None\n",
    "    # Remove currency, commas, and parentheses for negatives\n",
    "    s = series.astype(str)\n",
    "    s = s.str.replace(\"$\", \"\", regex=False)\n",
    "    s = s.str.replace(\",\", \"\", regex=False)\n",
    "    s = s.str.replace(\"%\", \"\", regex=False)\n",
    "    s = s.str.replace(\"(\", \"-\", regex=False)\n",
    "    s = s.str.replace(\")\", \"\", regex=False)\n",
    "    s = s.str.strip()\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def parse_date(series):\n",
    "    return pd.to_datetime(series, errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Load Schwab holdings CSV\n",
    "\n",
    "This function loads a holdings/positions export and normalizes columns into a consistent schema. It also calculates derived fields if missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_schwab_holdings(path):\n",
    "    if not Path(path).exists():\n",
    "        print(f\"Holdings CSV not found: {path}\")\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    df = normalize_columns(df)\n",
    "\n",
    "    # Standardize key numeric columns\n",
    "    for col in [\"quantity\", \"price\", \"market_value\", \"cost_basis\", \"unrealized_gain\", \"unrealized_gain_pct\", \"day_change\", \"day_change_pct\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = to_float(df[col])\n",
    "\n",
    "    # Derive market value if missing\n",
    "    if \"market_value\" not in df.columns and {\"quantity\", \"price\"}.issubset(df.columns):\n",
    "        df[\"market_value\"] = df[\"quantity\"] * df[\"price\"]\n",
    "\n",
    "    # Derive cost basis if missing\n",
    "    if \"cost_basis\" not in df.columns and \"unrealized_gain\" in df.columns and \"market_value\" in df.columns:\n",
    "        df[\"cost_basis\"] = df[\"market_value\"] - df[\"unrealized_gain\"]\n",
    "\n",
    "    # Derive unrealized gain if missing\n",
    "    if \"unrealized_gain\" not in df.columns and {\"market_value\", \"cost_basis\"}.issubset(df.columns):\n",
    "        df[\"unrealized_gain\"] = df[\"market_value\"] - df[\"cost_basis\"]\n",
    "\n",
    "    # Derive unrealized gain % if missing\n",
    "    if \"unrealized_gain_pct\" not in df.columns and {\"unrealized_gain\", \"cost_basis\"}.issubset(df.columns):\n",
    "        df[\"unrealized_gain_pct\"] = df[\"unrealized_gain\"] / df[\"cost_basis\"]\n",
    "\n",
    "    # Clean symbol\n",
    "    if \"symbol\" in df.columns:\n",
    "        df[\"symbol\"] = df[\"symbol\"].astype(str).str.strip()\n",
    "\n",
    "    # Drop rows without symbol or quantity\n",
    "    if \"symbol\" in df.columns:\n",
    "        df = df[df[\"symbol\"].notna()]\n",
    "\n",
    "    return df\n",
    "\n",
    "holdings = load_schwab_holdings(CONFIG[\"holdings_csv\"])\n",
    "holdings.head() if holdings is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Load Schwab transactions CSV (optional but recommended)\n",
    "\n",
    "Transactions provide the data needed for true performance metrics (TWR/MWR), realized gains, and cash flows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_schwab_transactions(path):\n",
    "    if not Path(path).exists():\n",
    "        print(f\"Transactions CSV not found: {path}\")\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    df = normalize_columns(df)\n",
    "\n",
    "    if \"trade_date\" in df.columns:\n",
    "        df[\"trade_date\"] = parse_date(df[\"trade_date\"])\n",
    "\n",
    "    for col in [\"quantity\", \"price\", \"amount\", \"fees\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = to_float(df[col])\n",
    "\n",
    "    if \"symbol\" in df.columns:\n",
    "        df[\"symbol\"] = df[\"symbol\"].astype(str).str.strip()\n",
    "\n",
    "    # Normalize action text\n",
    "    if \"action\" in df.columns:\n",
    "        df[\"action\"] = df[\"action\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "    return df\n",
    "\n",
    "transactions = load_schwab_transactions(CONFIG[\"transactions_csv\"])\n",
    "transactions.head() if transactions is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Data quality checks\n",
    "\n",
    "Before analysis, confirm the inputs are complete and consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdings_quality_report(df):\n",
    "    if df is None or df.empty:\n",
    "        return \"Holdings dataset is empty or missing.\"\n",
    "    report = {}\n",
    "    report[\"rows\"] = len(df)\n",
    "    for col in [\"symbol\", \"quantity\", \"price\", \"market_value\", \"cost_basis\"]:\n",
    "        report[f\"missing_{col}\"] = df[col].isna().mean() if col in df.columns else 1.0\n",
    "    report[\"zero_quantity\"] = (df.get(\"quantity\", pd.Series(dtype=float)) == 0).mean()\n",
    "    report[\"negative_market_value\"] = (df.get(\"market_value\", pd.Series(dtype=float)) < 0).mean()\n",
    "    return pd.Series(report)\n",
    "\n",
    "holdings_quality_report(holdings) if holdings is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Core portfolio summary\n",
    "\n",
    "Compute total market value, cost basis, unrealized gain, and exposures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_summary(df):\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    total_mv = df[\"market_value\"].sum() if \"market_value\" in df.columns else np.nan\n",
    "    total_cb = df[\"cost_basis\"].sum() if \"cost_basis\" in df.columns else np.nan\n",
    "    total_ug = df[\"unrealized_gain\"].sum() if \"unrealized_gain\" in df.columns else np.nan\n",
    "    total_ug_pct = total_ug / total_cb if pd.notna(total_cb) and total_cb != 0 else np.nan\n",
    "\n",
    "    summary = {\n",
    "        \"total_market_value\": total_mv,\n",
    "        \"total_cost_basis\": total_cb,\n",
    "        \"total_unrealized_gain\": total_ug,\n",
    "        \"total_unrealized_gain_pct\": total_ug_pct,\n",
    "        \"num_positions\": len(df),\n",
    "    }\n",
    "    return pd.Series(summary)\n",
    "\n",
    "summary = portfolio_summary(holdings)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weights(df):\n",
    "    if df is None or df.empty:\n",
    "        return df\n",
    "    total_mv = df[\"market_value\"].sum() if \"market_value\" in df.columns else np.nan\n",
    "    if pd.notna(total_mv) and total_mv != 0:\n",
    "        df = df.copy()\n",
    "        df[\"weight\"] = df[\"market_value\"] / total_mv\n",
    "    return df\n",
    "\n",
    "holdings = add_weights(holdings)\n",
    "holdings.head() if holdings is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Allocation and concentration analysis\n",
    "\n",
    "Compute allocation by symbol, asset class, and concentration metrics (HHI, top N).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentration_metrics(df):\n",
    "    if df is None or df.empty or \"weight\" not in df.columns:\n",
    "        return None\n",
    "    weights = df[\"weight\"].dropna().values\n",
    "    hhi = np.sum(weights ** 2)\n",
    "    top5 = df.nlargest(5, \"weight\")[\"weight\"].sum()\n",
    "    top10 = df.nlargest(10, \"weight\")[\"weight\"].sum()\n",
    "    return pd.Series({\n",
    "        \"hhi\": hhi,\n",
    "        \"top5_weight\": top5,\n",
    "        \"top10_weight\": top10,\n",
    "    })\n",
    "\n",
    "concentration_metrics(holdings) if holdings is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_positions(df, n=10):\n",
    "    if df is None or df.empty or \"weight\" not in df.columns:\n",
    "        return\n",
    "    top = df.nlargest(n, \"weight\").copy()\n",
    "    label_col = \"symbol\" if \"symbol\" in top.columns else top.index\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top[label_col].astype(str), top[\"weight\"], color=\"#4C72B0\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Top {n} Positions by Weight\")\n",
    "    plt.xlabel(\"Weight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_top_positions(holdings, n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Price data loading\n",
    "\n",
    "Price data is required for return, risk, and performance analytics. You can either:\n",
    "- Load a local CSV with columns: `date`, `symbol`, `adj_close` (or `close`)\n",
    "- Use `yfinance` to fetch prices (requires network access)\n",
    "\n",
    "The notebook supports both, but local CSV is most reliable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prices_local(path):\n",
    "    if not Path(path).exists():\n",
    "        print(f\"Prices CSV not found: {path}\")\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    df = normalize_columns(df)\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = parse_date(df[\"date\"])\n",
    "    if \"adj_close\" not in df.columns and \"close\" in df.columns:\n",
    "        df[\"adj_close\"] = df[\"close\"]\n",
    "    return df\n",
    "\n",
    "def fetch_prices_yfinance(symbols, period=\"5y\", interval=\"1d\"):\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception as e:\n",
    "        print(f\"yfinance not available: {e}\")\n",
    "        return None\n",
    "    data = yf.download(symbols, period=period, interval=interval, group_by=\"ticker\", auto_adjust=True, progress=False)\n",
    "    # Normalize to long format\n",
    "    if isinstance(symbols, str):\n",
    "        symbols = [symbols]\n",
    "    frames = []\n",
    "    for sym in symbols:\n",
    "        if sym in data.columns.get_level_values(0):\n",
    "            df = data[sym].reset_index()\n",
    "            df[\"symbol\"] = sym\n",
    "            df = df.rename(columns={\"Adj Close\": \"adj_close\", \"Close\": \"close\", \"Date\": \"date\"})\n",
    "            frames.append(df[[\"date\", \"symbol\", \"adj_close\"]])\n",
    "    return pd.concat(frames, ignore_index=True) if frames else None\n",
    "\n",
    "prices = load_prices_local(CONFIG[\"prices_csv\"])\n",
    "if prices is None and CONFIG[\"use_yfinance\"] and holdings is not None:\n",
    "    symbols = sorted(set(holdings[\"symbol\"].dropna().astype(str)))\n",
    "    symbols = [s for s in symbols if s not in [\"CASH\", \"USD\"]]\n",
    "    prices = fetch_prices_yfinance(symbols + [CONFIG[\"benchmark_symbol\"]], CONFIG[\"yfinance_period\"], CONFIG[\"yfinance_interval\"])\n",
    "prices.head() if prices is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Returns and risk analytics\n",
    "\n",
    "With price history, compute returns, volatility, beta, drawdown, and risk metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_price_matrix(prices_df):\n",
    "    if prices_df is None or prices_df.empty:\n",
    "        return None\n",
    "    df = prices_df.copy()\n",
    "    df = df.dropna(subset=[\"date\", \"symbol\", \"adj_close\"])\n",
    "    df = df.sort_values([\"symbol\", \"date\"])\n",
    "    pivot = df.pivot(index=\"date\", columns=\"symbol\", values=\"adj_close\")\n",
    "    return pivot\n",
    "\n",
    "price_matrix = build_price_matrix(prices)\n",
    "price_matrix.tail() if price_matrix is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(price_matrix, method=\"log\"):\n",
    "    if price_matrix is None or price_matrix.empty:\n",
    "        return None\n",
    "    if method == \"log\":\n",
    "        returns = np.log(price_matrix / price_matrix.shift(1))\n",
    "    else:\n",
    "        returns = price_matrix.pct_change()\n",
    "    return returns.dropna(how=\"all\")\n",
    "\n",
    "returns = compute_returns(price_matrix, method=\"log\")\n",
    "returns.tail() if returns is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_returns(returns_df, weights):\n",
    "    if returns_df is None or returns_df.empty:\n",
    "        return None\n",
    "    # Align weights to columns\n",
    "    w = weights.reindex(returns_df.columns).fillna(0.0)\n",
    "    port = returns_df.mul(w, axis=1).sum(axis=1)\n",
    "    return port\n",
    "\n",
    "if holdings is not None and \"weight\" in holdings.columns and returns is not None:\n",
    "    weights = holdings.set_index(\"symbol\")[\"weight\"]\n",
    "    port_rets = portfolio_returns(returns, weights)\n",
    "else:\n",
    "    port_rets = None\n",
    "\n",
    "port_rets.tail() if port_rets is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_metrics(port_rets, benchmark_rets=None, rf_annual=0.03):\n",
    "    if port_rets is None or port_rets.empty:\n",
    "        return None\n",
    "    rf_daily = (1 + rf_annual) ** (1/252) - 1\n",
    "    excess = port_rets - rf_daily\n",
    "\n",
    "    ann_return = port_rets.mean() * 252\n",
    "    ann_vol = port_rets.std() * np.sqrt(252)\n",
    "    sharpe = excess.mean() / port_rets.std() * np.sqrt(252) if port_rets.std() != 0 else np.nan\n",
    "\n",
    "    # Drawdown\n",
    "    cum = (1 + port_rets).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    drawdown = (cum - peak) / peak\n",
    "    max_dd = drawdown.min()\n",
    "\n",
    "    results = {\n",
    "        \"annualized_return\": ann_return,\n",
    "        \"annualized_volatility\": ann_vol,\n",
    "        \"sharpe_ratio\": sharpe,\n",
    "        \"max_drawdown\": max_dd,\n",
    "    }\n",
    "\n",
    "    if benchmark_rets is not None and not benchmark_rets.empty:\n",
    "        cov = np.cov(port_rets.align(benchmark_rets, join=\"inner\")[0], benchmark_rets.align(port_rets, join=\"inner\")[0])[0, 1]\n",
    "        beta = cov / np.var(benchmark_rets) if np.var(benchmark_rets) != 0 else np.nan\n",
    "        results[\"beta_vs_benchmark\"] = beta\n",
    "\n",
    "    return pd.Series(results)\n",
    "\n",
    "if returns is not None and CONFIG[\"benchmark_symbol\"] in returns.columns and port_rets is not None:\n",
    "    bench = returns[CONFIG[\"benchmark_symbol\"]].dropna()\n",
    "else:\n",
    "    bench = None\n",
    "\n",
    "risk_metrics(port_rets, bench, CONFIG[\"risk_free_rate_annual\"]) if port_rets is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Correlations and diversification\n",
    "\n",
    "Compute correlation matrix and visualize it. Use this to identify clustering and diversification gaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(returns_df, max_symbols=25):\n",
    "    if returns_df is None or returns_df.empty:\n",
    "        return\n",
    "    # Limit to top positions by weight (if available)\n",
    "    cols = list(returns_df.columns)\n",
    "    if holdings is not None and \"weight\" in holdings.columns:\n",
    "        top_syms = holdings.nlargest(max_symbols, \"weight\")[\"symbol\"].tolist()\n",
    "        cols = [c for c in cols if c in top_syms]\n",
    "    corr = returns_df[cols].corr()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True)\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation_matrix(returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Risk contribution (marginal and total)\n",
    "\n",
    "Quantify how much each position contributes to total portfolio risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_contribution(returns_df, weights):\n",
    "    if returns_df is None or returns_df.empty:\n",
    "        return None\n",
    "    cov = returns_df.cov() * 252\n",
    "    w = weights.reindex(cov.index).fillna(0.0)\n",
    "    port_var = np.dot(w, np.dot(cov, w))\n",
    "    if port_var == 0:\n",
    "        return None\n",
    "    mrc = np.dot(cov, w) / np.sqrt(port_var)\n",
    "    trc = w * mrc\n",
    "    out = pd.DataFrame({\n",
    "        \"weight\": w,\n",
    "        \"marginal_risk_contrib\": mrc,\n",
    "        \"total_risk_contrib\": trc,\n",
    "        \"total_risk_contrib_pct\": trc / trc.sum()\n",
    "    })\n",
    "    return out.sort_values(\"total_risk_contrib_pct\", ascending=False)\n",
    "\n",
    "if returns is not None and holdings is not None and \"weight\" in holdings.columns:\n",
    "    weights = holdings.set_index(\"symbol\")[\"weight\"]\n",
    "    risk_contrib = risk_contribution(returns, weights)\n",
    "else:\n",
    "    risk_contrib = None\n",
    "\n",
    "risk_contrib.head(10) if risk_contrib is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Transaction-based performance (TWR and MWR)\n",
    "\n",
    "If you have transactions, you can compute time-weighted return (TWR) and money-weighted return (MWR/IRR).\n",
    "\n",
    "This section is more advanced and depends on clean transaction data. If your Schwab CSV uses different action labels, update the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cash_flow(df):\n",
    "    if df is None or df.empty or \"action\" not in df.columns:\n",
    "        return None\n",
    "    df = df.copy()\n",
    "    # Simple heuristic: buys are negative cash flows, sells and dividends positive\n",
    "    buys = df[\"action\"].str.contains(\"buy\", na=False)\n",
    "    sells = df[\"action\"].str.contains(\"sell\", na=False)\n",
    "    divs = df[\"action\"].str.contains(\"div\", na=False)\n",
    "    contrib = df[\"action\"].str.contains(\"contribution|deposit\", na=False)\n",
    "    withdraw = df[\"action\"].str.contains(\"withdrawal\", na=False)\n",
    "\n",
    "    df[\"cash_flow\"] = 0.0\n",
    "    if \"amount\" in df.columns:\n",
    "        df.loc[buys, \"cash_flow\"] = -df.loc[buys, \"amount\"]\n",
    "        df.loc[sells | divs | contrib, \"cash_flow\"] = df.loc[sells | divs | contrib, \"amount\"]\n",
    "        df.loc[withdraw, \"cash_flow\"] = -df.loc[withdraw, \"amount\"]\n",
    "    return df\n",
    "\n",
    "def compute_mwr(cash_flows):\n",
    "    # Money-weighted return using IRR of cash flows\n",
    "    if cash_flows is None or cash_flows.empty:\n",
    "        return None\n",
    "    cf = cash_flows.dropna(subset=[\"trade_date\", \"cash_flow\"]).copy()\n",
    "    cf = cf.sort_values(\"trade_date\")\n",
    "    # Aggregate by date\n",
    "    cf = cf.groupby(\"trade_date\")[\"cash_flow\"].sum()\n",
    "    # Add ending market value as a final positive flow (if available)\n",
    "    if holdings is not None and \"market_value\" in holdings.columns:\n",
    "        end_value = holdings[\"market_value\"].sum()\n",
    "        cf.loc[pd.Timestamp(datetime.today().date())] = cf.get(pd.Timestamp(datetime.today().date()), 0) + end_value\n",
    "    # IRR approximation using numpy.irr on equally spaced periods\n",
    "    try:\n",
    "        irr = np.irr(cf.values)\n",
    "    except Exception:\n",
    "        irr = np.nan\n",
    "    return irr\n",
    "\n",
    "if transactions is not None:\n",
    "    cf = classify_cash_flow(transactions)\n",
    "    mwr = compute_mwr(cf)\n",
    "else:\n",
    "    cf = None\n",
    "    mwr = None\n",
    "\n",
    "mwr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Stress tests and scenarios\n",
    "\n",
    "Run simple stress scenarios across holdings. Adjust the scenarios based on your risk tolerance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress_test(df, shocks=None):\n",
    "    if df is None or df.empty or \"market_value\" not in df.columns:\n",
    "        return None\n",
    "    if shocks is None:\n",
    "        shocks = {\n",
    "            \"equity_down_10\": -0.10,\n",
    "            \"equity_down_20\": -0.20,\n",
    "            \"equity_down_30\": -0.30,\n",
    "        }\n",
    "    total = df[\"market_value\"].sum()\n",
    "    out = {}\n",
    "    for name, shock in shocks.items():\n",
    "        out[name] = total * (1 + shock)\n",
    "    return pd.Series(out)\n",
    "\n",
    "stress_test(holdings) if holdings is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Rebalancing diagnostics\n",
    "\n",
    "Define target weights and compute drift. This is optional but useful for disciplined portfolio management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example target weights (customize to your strategy)\n",
    "TARGET_WEIGHTS = {\n",
    "    # \"AAPL\": 0.05,\n",
    "    # \"SPY\": 0.30,\n",
    "}\n",
    "\n",
    "def rebalance_table(df, targets):\n",
    "    if df is None or df.empty or \"weight\" not in df.columns:\n",
    "        return None\n",
    "    out = df.copy()\n",
    "    out[\"target_weight\"] = out[\"symbol\"].map(targets).fillna(0.0)\n",
    "    out[\"drift\"] = out[\"weight\"] - out[\"target_weight\"]\n",
    "    out = out.sort_values(\"drift\", ascending=False)\n",
    "    return out[[\"symbol\", \"weight\", \"target_weight\", \"drift\", \"market_value\"]]\n",
    "\n",
    "rebalance = rebalance_table(holdings, TARGET_WEIGHTS)\n",
    "rebalance.head(10) if rebalance is not None else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Exports\n",
    "\n",
    "Export data tables and figures to `outputs/` for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tables():\n",
    "    if holdings is not None:\n",
    "        holdings.to_csv(OUTPUT_DIR / \"holdings_normalized.csv\", index=False)\n",
    "    if transactions is not None:\n",
    "        transactions.to_csv(OUTPUT_DIR / \"transactions_normalized.csv\", index=False)\n",
    "    if risk_contrib is not None:\n",
    "        risk_contrib.to_csv(OUTPUT_DIR / \"risk_contribution.csv\", index=True)\n",
    "    if rebalance is not None:\n",
    "        rebalance.to_csv(OUTPUT_DIR / \"rebalance.csv\", index=False)\n",
    "    print(f\"Exports written to: {OUTPUT_DIR}\")\n",
    "\n",
    "# export_tables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Next steps and customization\n",
    "\n",
    "Ideas to make this even more comprehensive:\n",
    "- Add tax lot analysis if you export lots from Schwab\n",
    "- Incorporate dividends by mapping transactions to dividends\n",
    "- Add factor exposures (value, momentum, quality)\n",
    "- Integrate custom benchmarks or multi-asset indexes\n",
    "- Build a rolling risk dashboard (30/90/252 day windows)\n",
    "\n",
    "If you provide sample CSVs, this notebook can be tailored precisely to your export format.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
